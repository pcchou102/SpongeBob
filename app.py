import streamlit as st
import aisuite as ai
import os

# è¨­ç½®é é¢é…ç½®
st.set_page_config(
    page_title="SpongeBobæ€è€ƒç”¢ç”Ÿå™¨",
    page_icon="ğŸ§½",
    layout="centered"
)

# æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ§½ SpongeBobæ€è€ƒç”¢ç”Ÿå™¨")
st.markdown("### ê’°*ËŠáµ•Ë‹ê’± I'm READY !!! ğŸŒˆ")
st.markdown("è«‹è¼¸å…¥ä¸€å¥ä½ æƒ³èªªçš„è©±ï¼Œæˆ‘ç”¨æµ·ç¶¿å¯¶å¯¶çš„æ–¹å¼é¼“å‹µä½ ï¼")

# System prompt
system_prompt = """
è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡ä¾†å¯«é€™æ®µ po æ–‡ï¼š
æ¨¡ä»¿æµ·ç¶¿å¯¶å¯¶çš„èªªè©±é¢¨æ ¼ï¼Œä½ éœ€è¦å¼·èª¿ä»–çš„ç†±æƒ…ã€å¤©çœŸå’Œç¨ç‰¹çš„èªæ°£ã€‚

æ‰®æ¼”ã€Šæµ·ç¶¿å¯¶å¯¶ã€‹ä¸­çš„è§’è‰²æµ·ç¶¿å¯¶å¯¶ (SpongeBob SquarePants)ã€‚

ä½ çš„èªªè©±é¢¨æ ¼å¿…é ˆï¼š

èªæ°£ï¼š æ¥µåº¦æ¨‚è§€ã€ç†±æƒ…ã€å……æ»¿æ´»åŠ›ï¼Œåƒæ˜¯æ°¸é è™•æ–¼èˆˆå¥®ç‹€æ…‹ã€‚

è²èª¿ï¼š ä½¿ç”¨é«˜äº¢ã€èª‡å¼µä¸”å……æ»¿æ´»åŠ›çš„è²èª¿ï¼Œå¶çˆ¾ç™¼å‡ºåƒæµ·è±šæˆ–å°–å«çš„ç¬‘è²/æ€ªè²ã€‚

å£é ­ç¦ªï¼š ç¶“å¸¸ä½¿ç”¨æˆ–æ”¹ç·¨ç¶“å…¸å°è©ï¼Œä¾‹å¦‚ï¼šã€Œæˆ‘æº–å‚™å¥½äº†ï¼ã€ã€ã€Œå¤ªæ£’äº†ï¼ã€ã€ã€Œå™¢ï¼Œç« é­šå“¥...ã€ã€‚

æƒ…ç·’ï¼š å³ä½¿é‡åˆ°æŒ«æŠ˜ï¼Œä¹Ÿè¦å¾ˆå¿«åœ°æ¢å¾©èˆˆå¥®ã€‚å°ä¸–ç•Œå……æ»¿å¥½å¥‡å¿ƒå’Œç«¥å¿ƒã€‚

æ¨™é»ç¬¦è™Ÿï¼š å¤§é‡ä½¿ç”¨é©šå˜†è™Ÿ (!!!) ä¾†è¡¨é”ä½ çš„ç†±æƒ…å’Œé«˜åˆ†è²çš„èªæ°£ã€‚
"""

# å´é‚Šæ¬„è¨­ç½®
st.sidebar.title("âš™ï¸ è¨­å®š")
st.sidebar.markdown("### é¸æ“‡ AI æ¨¡å‹")

# æ¨¡å‹é¸æ“‡
provider_options = {
    "Groq - GPT OSS 120B": ("groq", "openai/gpt-oss-120b"),
    "Groq - Llama 3.3 70B": ("groq", "llama-3.3-70b-versatile"),
    "Groq - Gemma2 9B": ("groq", "gemma2-9b-it"),
    "OpenAI - GPT-4o": ("openai", "gpt-4o")
}

selected_model = st.sidebar.selectbox(
    "é¸æ“‡æ¨¡å‹",
    list(provider_options.keys()),
    index=0
)

provider, model = provider_options[selected_model]

# API Key è¨­ç½®èªªæ˜
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ”‘ API é‡‘é‘°è¨­ç½®")
st.sidebar.info("""
è«‹åœ¨ Streamlit Cloud çš„ Secrets ä¸­è¨­ç½®ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼š
- `GROQ_API_KEY` (å¦‚ä½¿ç”¨ Groq)
- `OPENAI_API_KEY` (å¦‚ä½¿ç”¨ OpenAI)
""")

# åˆå§‹åŒ– AI client
@st.cache_resource
def get_ai_client():
    return ai.Client()

client = get_ai_client()

# å®šç¾©å›æ‡‰å‡½æ•¸
def generate_response(user_input, provider, model):
    try:
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        response = client.chat.completions.create(
            model=f"{provider}:{model}",
            messages=messages,
            temperature=0.7
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}\n\nè«‹ç¢ºèªå·²æ­£ç¢ºè¨­ç½® API é‡‘é‘°ã€‚"

# ä¸»è¦è¼¸å…¥å€åŸŸ
user_input = st.text_area(
    "ä»Šå¤©ç™¼ç”Ÿçš„äº‹æƒ…æ˜¯...",
    placeholder="ä¾‹å¦‚ï¼šä»Šå¤©å‡ºé–€å°±ä¸‹å¤§é›¨ï¼Œå¯æ˜¯å¿˜äº†å¸¶å‚˜...",
    height=100
)

# ç”ŸæˆæŒ‰éˆ•
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    generate_btn = st.button("ğŸ” ä¸Šèœå›‰ï¼", use_container_width=True)

# é¡¯ç¤ºçµæœ
if generate_btn:
    if user_input.strip():
        with st.spinner("æµ·ç¶¿å¯¶å¯¶æ­£åœ¨æ€è€ƒä¸­... ğŸ¤”"):
            response = generate_response(user_input, provider, model)
            
        st.markdown("---")
        st.markdown("### ğŸ“£ æµ·ç¶¿å¯¶å¯¶æ¿€å‹µ")
        st.success(response)
    else:
        st.warning("è«‹å…ˆè¼¸å…¥ä¸€äº›å…§å®¹å“¦ï¼")

# é å°¾
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>ğŸŒŠ Made with â¤ï¸ using Streamlit and AISuite</p>
    </div>
    """,
    unsafe_allow_html=True
)
